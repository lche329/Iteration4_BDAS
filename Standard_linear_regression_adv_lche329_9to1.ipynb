{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Must be included at the beginning of each new notebook. Remember to change the app name.\n",
    "import findspark\n",
    "findspark.init('/home/user/spark-2.1.1-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('linear_regression_adv_lche329_9to1').getOrCreate()\n",
    "\n",
    "# If you're getting an error with numpy, please type 'sudo pip install numpy --user' into the EC2 console.\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.load('./Sales_data/sales_en.csv',format='csv',header='true',inferSchema = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Unit: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Sales Representative: string (nullable = true)\n",
      " |-- Hospital Name: string (nullable = true)\n",
      " |-- Hospital Attribute: string (nullable = true)\n",
      " |-- Hospital Code: string (nullable = true)\n",
      " |-- Purchasing Price: double (nullable = true)\n",
      " |-- Selling Price: double (nullable = true)\n",
      " |-- IMF: string (nullable = true)\n",
      " |-- Hospital Class: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Client Name: string (nullable = true)\n",
      " |-- Sales Volume: double (nullable = true)\n",
      " |-- Profits: double (nullable = true)\n",
      " |-- Satisfaction: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the schema of the DataFrame. You can see potential features as well as the predictor.\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(ID=1, Year=2016, Product Name='Corbrin Capsule', Unit='Dept. 2', Region='Wuhan', Sales Representative='Xiongting', Hospital Name='Huazhongkejidaxuetongjiyixueyuanfushuxieheyiyuan', Hospital Attribute='Ministerial hospital', Hospital Code='ADXH', Purchasing Price=47.14, Selling Price=63.14, IMF='1571181790', Hospital Class='Third Class', Department='Shenneike', Client Name='Denganguo', Sales Volume=236.0, Profits=3776.0, Satisfaction='Y')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2016\n",
      "Corbrin Capsule\n",
      "Dept. 2\n",
      "Wuhan\n",
      "Xiongting\n",
      "Huazhongkejidaxuetongjiyixueyuanfushuxieheyiyuan\n",
      "Ministerial hospital\n",
      "ADXH\n",
      "47.14\n",
      "63.14\n",
      "1571181790\n",
      "Third Class\n",
      "Shenneike\n",
      "Denganguo\n",
      "236.0\n",
      "3776.0\n",
      "Y\n"
     ]
    }
   ],
   "source": [
    "# A simple for loop allows us to make it even clearer. \n",
    "for item in df.head():\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VectorAssembler and Vectors\n",
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input columns are the feature column names, and the output column is what you'd like the new column to be named. \n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Sales Representative\", \"Hospital Attribute\", \n",
    "               \"Selling Price\",\"Hospital Class\",\"Department\",\"Sales Volume\"],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "\n",
    "indexer = StringIndexer(inputCol=\"Sales Representative\", outputCol=\"Sales_Representative_Index\")\n",
    "df_indexed = indexer.fit(df).transform(df)\n",
    "indexer = StringIndexer(inputCol=\"Hospital Attribute\", outputCol=\"Hospital_Attribute_Index\")\n",
    "df_indexed = indexer.fit(df_indexed).transform(df_indexed)\n",
    "indexer = StringIndexer(inputCol=\"Hospital Class\", outputCol=\"Hospital_Class_Index\")\n",
    "df_indexed = indexer.fit(df_indexed).transform(df_indexed)\n",
    "indexer = StringIndexer(inputCol=\"Department\", outputCol=\"Department_Index\")\n",
    "df_indexed = indexer.fit(df_indexed).transform(df_indexed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Unit: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Sales Representative: string (nullable = true)\n",
      " |-- Hospital Name: string (nullable = true)\n",
      " |-- Hospital Attribute: string (nullable = true)\n",
      " |-- Hospital Code: string (nullable = true)\n",
      " |-- Purchasing Price: double (nullable = true)\n",
      " |-- Selling Price: double (nullable = true)\n",
      " |-- IMF: string (nullable = true)\n",
      " |-- Hospital Class: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Client Name: string (nullable = true)\n",
      " |-- Sales Volume: double (nullable = true)\n",
      " |-- Profits: double (nullable = true)\n",
      " |-- Satisfaction: string (nullable = true)\n",
      " |-- Sales_Representative_Index: double (nullable = true)\n",
      " |-- Hospital_Attribute_Index: double (nullable = true)\n",
      " |-- Hospital_Class_Index: double (nullable = true)\n",
      " |-- Department_Index: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_indexed.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The input columns are the feature column names, and the output column is what you'd like the new column to be named. \n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Sales_Representative_Index\", \"Hospital_Attribute_Index\", \n",
    "               \"Selling Price\",\"Hospital_Class_Index\",\"Department_Index\",\"Sales Volume\"],\n",
    "    outputCol=\"features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that we've created the assembler variable, let's actually transform the data.\n",
    "output = assembler.transform(df_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- ID: integer (nullable = true)\n",
      " |-- Year: integer (nullable = true)\n",
      " |-- Product Name: string (nullable = true)\n",
      " |-- Unit: string (nullable = true)\n",
      " |-- Region: string (nullable = true)\n",
      " |-- Sales Representative: string (nullable = true)\n",
      " |-- Hospital Name: string (nullable = true)\n",
      " |-- Hospital Attribute: string (nullable = true)\n",
      " |-- Hospital Code: string (nullable = true)\n",
      " |-- Purchasing Price: double (nullable = true)\n",
      " |-- Selling Price: double (nullable = true)\n",
      " |-- IMF: string (nullable = true)\n",
      " |-- Hospital Class: string (nullable = true)\n",
      " |-- Department: string (nullable = true)\n",
      " |-- Client Name: string (nullable = true)\n",
      " |-- Sales Volume: double (nullable = true)\n",
      " |-- Profits: double (nullable = true)\n",
      " |-- Satisfaction: string (nullable = true)\n",
      " |-- Sales_Representative_Index: double (nullable = true)\n",
      " |-- Hospital_Attribute_Index: double (nullable = true)\n",
      " |-- Hospital_Class_Index: double (nullable = true)\n",
      " |-- Department_Index: double (nullable = true)\n",
      " |-- features: vector (nullable = true)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(ID=1, Year=2016, Product Name='Corbrin Capsule', Unit='Dept. 2', Region='Wuhan', Sales Representative='Xiongting', Hospital Name='Huazhongkejidaxuetongjiyixueyuanfushuxieheyiyuan', Hospital Attribute='Ministerial hospital', Hospital Code='ADXH', Purchasing Price=47.14, Selling Price=63.14, IMF='1571181790', Hospital Class='Third Class', Department='Shenneike', Client Name='Denganguo', Sales Volume=236.0, Profits=3776.0, Satisfaction='Y', Sales_Representative_Index=139.0, Hospital_Attribute_Index=3.0, Hospital_Class_Index=0.0, Department_Index=3.0, features=DenseVector([139.0, 3.0, 63.14, 0.0, 3.0, 236.0]))]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using print schema, you see that the features output column has been added. \n",
    "output.printSchema()\n",
    "\n",
    "# You can see that the features column is a dense vector that combines the various features as expected.\n",
    "output.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+\n",
      "|            features|Profits|\n",
      "+--------------------+-------+\n",
      "|[139.0,3.0,63.14,...| 3776.0|\n",
      "|[139.0,3.0,63.14,...| 5072.0|\n",
      "|[139.0,3.0,63.14,...| 4592.0|\n",
      "|[139.0,3.0,63.14,...| 2560.0|\n",
      "|[139.0,3.0,63.14,...| 1920.0|\n",
      "|[139.0,3.0,63.14,...| 1104.0|\n",
      "|[139.0,3.0,63.14,...| 2064.0|\n",
      "|[139.0,3.0,63.14,...| 2752.0|\n",
      "|[139.0,3.0,63.14,...| 3392.0|\n",
      "|[139.0,3.0,63.14,...| 4960.0|\n",
      "|[139.0,3.0,63.14,...| 2448.0|\n",
      "|[139.0,3.0,63.14,...|  288.0|\n",
      "|[139.0,3.0,63.14,...|    0.0|\n",
      "|[139.0,3.0,63.14,...|    0.0|\n",
      "|[139.0,3.0,63.14,...| 3536.0|\n",
      "|[139.0,3.0,63.14,...|    0.0|\n",
      "|[139.0,3.0,63.14,...| 9488.0|\n",
      "|[139.0,3.0,63.14,...|17760.0|\n",
      "|[139.0,3.0,63.14,...|  336.0|\n",
      "|[139.0,3.0,63.14,...|  336.0|\n",
      "+--------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's select two columns (the feature and predictor).\n",
    "# This is now in the appropriate format to be processed by Spark.\n",
    "final_data = output.select(\"features\",'Profits')\n",
    "final_data.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a randomised 90/10 split. \n",
    "# Remember, you can use other splits depending on how easy/difficult it is to train your model.\n",
    "train_data,test_data = final_data.randomSplit([0.9,0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|summary|          Profits|\n",
      "+-------+-----------------+\n",
      "|  count|            36297|\n",
      "|   mean|235.6644846958471|\n",
      "| stddev|925.6205266664939|\n",
      "|    min|          -130.02|\n",
      "|    max|          38656.0|\n",
      "+-------+-----------------+\n",
      "\n",
      "+-------+------------------+\n",
      "|summary|           Profits|\n",
      "+-------+------------------+\n",
      "|  count|              3988|\n",
      "|   mean|225.89975993150935|\n",
      "| stddev| 805.2986763452868|\n",
      "|    min|           -130.02|\n",
      "|    max|          19545.44|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's see our training data.\n",
    "train_data.describe().show()\n",
    "\n",
    "# And our testing data.\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now we can create a Linear Regression Model object. Because the feature column is named 'features', we don't have to worry about it. However, as the labelCol isn't the default name, we have to specify it's name (Yearly Amount Spent).\n",
    "lr = LinearRegression(labelCol='Profits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model to the data.\n",
    "lrModel = lr.fit(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [0.5958284327906072,4.365876133292106,0.25511776627316773,37.44152490745029,2.823427088908967,11.743613304851769] Intercept: -75.82762040366998\n"
     ]
    }
   ],
   "source": [
    "# Print the coefficients and intercept for linear regression.\n",
    "print(\"Coefficients: {} Intercept: {}\".format(lrModel.coefficients,lrModel.intercept))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's evaluate the model against the test data.\n",
    "test_results = lrModel.evaluate(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|          residuals|\n",
      "+-------------------+\n",
      "| 58.527827775600954|\n",
      "| 58.527827775600954|\n",
      "| 58.527827775600954|\n",
      "| 58.527827775600954|\n",
      "|  55.99500435748696|\n",
      "|  48.99457285095124|\n",
      "|  48.69863624207437|\n",
      "|  48.69863624207437|\n",
      "|  42.14452348137769|\n",
      "|  34.09886203118606|\n",
      "|  34.09886203118606|\n",
      "|  26.94892083769878|\n",
      "| 15.928072438590974|\n",
      "| 22.628612121212967|\n",
      "|  9.074067853980551|\n",
      "|  4.307440391655703|\n",
      "|  4.307440391655703|\n",
      "|  4.307440391655703|\n",
      "| -6.024727383653541|\n",
      "|-10.185705921786251|\n",
      "+-------------------+\n",
      "only showing top 20 rows\n",
      "\n",
      "RSME_Standard: 475.20925575764477\n"
     ]
    }
   ],
   "source": [
    "# Interesting results! This shows the difference between the predicted value and the test data.\n",
    "test_results.residuals.show()\n",
    "\n",
    "# Let's get some evaluation metrics (as discussed in the previous linear regression notebook).\n",
    "print(\"RSME_Standard: {}\".format(test_results.rootMeanSquaredError))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2_Standard: 0.6516909768251571\n"
     ]
    }
   ],
   "source": [
    "# We can also get the R2 value. \n",
    "print(\"R2_Standard: {}\".format(test_results.r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|summary|           Profits|\n",
      "+-------+------------------+\n",
      "|  count|             40285|\n",
      "|   mean|234.69782905826548|\n",
      "| stddev| 914.4112274804912|\n",
      "|    min|           -130.02|\n",
      "|    max|           38656.0|\n",
      "+-------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_data.describe().show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
